import streamlit as st
import json
from utils import get_relevant_info, clean_gemini_json, render_process_status
from services.gemini_api import call_gemini_api, call_gemini_stream
from services.supabase_db import log_query_event
from prompts import get_persona_generation_prompt, get_persona_chat_instruction
import constants as c
from reporting.pdf_generator import generate_pdf_html
from config import banner_file

def synthetic_users_mode(db, selected_files):
    st.subheader("Perfil SintÃ©tico")
    st.markdown("Simula conversaciones con perfiles de consumidor generados a partir de tus datos reales.")
    
    # 1. CONFIGURACIÃ“N DEL PERFIL
    show_config = "synthetic_persona_data" not in st.session_state.mode_state
    
    with st.expander("Configurar Perfil SintÃ©tico", expanded=show_config):
        segment_name = st.text_input("Nombre del Segmento a simular:", placeholder="Ej: Compradores sensibles al precio, MamÃ¡s primerizas...")
        
        if st.button("Generar ADN del Perfil", type="primary", use_container_width=True):
            if not selected_files:
                st.warning("âš ï¸ Selecciona documentos en el menÃº lateral.")
                return
            
            if not segment_name: 
                st.warning("âš ï¸ Define un nombre para el segmento.")
                return
            
            with render_process_status("Analizando datos y construyendo psique...", expanded=True) as status:
                
                # A. Buscar contexto
                status.write("ðŸ” Escaneando documentos...")
                context = get_relevant_info(db, segment_name, selected_files)
                
                if not context: 
                    status.update(label="No hay datos suficientes.", state="error")
                    return
                
                # B. Generar Perfil
                status.write("DiseÃ±ando personalidad...")
                prompt = get_persona_generation_prompt(segment_name, context)
                
                resp = call_gemini_api(prompt, generation_config_override={"response_mime_type": "application/json"})
                
                if resp: 
                    try:
                        clean_resp = clean_gemini_json(resp)
                        persona_data = json.loads(clean_resp)
                        
                        # --- CORRECCIÃ“N DE LISTA ---
                        if isinstance(persona_data, list):
                            if len(persona_data) > 0:
                                persona_data = persona_data[0]
                            else:
                                raise ValueError("La IA devolviÃ³ una lista vacÃ­a.")
                        
                        # --- CORRECCIÃ“N DE LLAVES (NORMALIZACIÃ“N) ---
                        # Convertimos todas las llaves a minÃºscula para evitar errores como "Nombre" vs "nombre"
                        persona_data = {k.lower(): v for k, v in persona_data.items()}
                        
                        # Validar campos mÃ­nimos
                        if "nombre" not in persona_data:
                            # Intento de rescate si la IA usÃ³ otra estructura (ej: nested)
                            pass 

                        st.session_state.mode_state["synthetic_persona_data"] = persona_data
                        st.session_state.mode_state["synthetic_chat_history"] = [] 
                        
                        # Log
                        try:
                            log_query_event(f"Persona: {segment_name}", mode=c.MODE_SYNTHETIC)
                        except: pass
                        
                        status.update(label="Â¡Perfil Creado!", state="complete", expanded=False)
                        st.rerun()
                        
                    except Exception as e:
                        status.update(label="Error de formato", state="error")
                        st.error(f"Error procesando la respuesta de la IA: {e}")
                        with st.expander("Ver respuesta cruda (Debug)"):
                            st.code(resp)
                else:
                    status.update(label="Error de conexiÃ³n con IA", state="error")

    # 2. VISUALIZACIÃ“N DEL PERFIL Y CHAT
    if "synthetic_persona_data" in st.session_state.mode_state:
        p = st.session_state.mode_state["synthetic_persona_data"]
        
        if not isinstance(p, dict):
            st.error("Error: Datos corruptos.")
            if st.button("Reiniciar"):
                st.session_state.mode_state.pop("synthetic_persona_data")
                st.rerun()
            return

        st.divider()
        
        col_img, col_info = st.columns([1, 4])
        with col_img:
            st.markdown(f"<div style='font-size: 80px; text-align: center; line-height: 1;'>ðŸ‘¤</div>", unsafe_allow_html=True)
        with col_info:
            # Usamos get con valores por defecto y normalizados
            st.markdown(f"### {p.get('nombre', 'Usuario Simulado')}")
            st.caption(f"{p.get('edad', 'Edad N/A')} | {p.get('ocupacion', 'OcupaciÃ³n N/A')}")
            st.info(f"**Bio:** {p.get('bio_breve', 'Sin biografÃ­a disponible.')}")
            
        with st.expander("Ver detalles psicolÃ³gicos (Dolores y Motivadores)"):
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("**Dolores:**")
                # Si falla, mostramos mensaje amigable en vez de []
                dolores = p.get('dolores_principales', [])
                if dolores:
                    for d in dolores: st.write(f"- {d}")
                else:
                    st.write("No identificados.")
                    
            with c2:
                st.markdown("**Motivadores:**")
                motivadores = p.get('motivadores_compra', [])
                if motivadores:
                    for m in motivadores: st.write(f"- {m}")
                else:
                    st.write("No identificados.")
            
            st.write("")
            st.markdown(f"**Estilo:** *{p.get('estilo_comunicacion', 'EstÃ¡ndar')}*")

        # 3. CHAT
        st.divider()
        st.markdown(f"#### ðŸ’¬ Entrevista a {p.get('nombre', 'Usuario')}")
        
        if "synthetic_chat_history" not in st.session_state.mode_state:
            st.session_state.mode_state["synthetic_chat_history"] = []
            
        for msg in st.session_state.mode_state["synthetic_chat_history"]:
            role = msg['role']
            name = "Entrevistador" if role == "user" else p.get('nombre', 'Usuario')
            avatar = "ðŸŽ¤" if role == "user" else "ðŸ‘¤"
            
            with st.chat_message(name, avatar=avatar):
                st.markdown(msg['content'])

        user_question = st.chat_input(f"Hazle una pregunta a {p.get('nombre', 'Usuario')}...")
        
        if user_question:
            st.session_state.mode_state["synthetic_chat_history"].append({"role": "user", "content": user_question})
            with st.chat_message("Entrevistador", avatar="ðŸŽ¤"):
                st.markdown(user_question)
            
            with st.chat_message(p.get('nombre', 'Usuario'), avatar="ðŸ‘¤"):
                with st.spinner(f"{p.get('nombre')} estÃ¡ pensando..."):
                    acting_prompt = get_persona_chat_instruction(p, user_question)
                    stream = call_gemini_stream(acting_prompt)
                    if stream:
                        response = st.write_stream(stream)
                        st.session_state.mode_state["synthetic_chat_history"].append({"role": "assistant", "content": response})

        # --- ACCIONES ---
        if st.session_state.mode_state["synthetic_chat_history"]:
            st.divider()
            c1, c2, c3 = st.columns(3)
            
            with c1:
                chat_content = f"# Entrevista con Perfil SintÃ©tico: {p.get('nombre')}\n\n"
                chat_content += f"**Perfil:** {p.get('edad')}, {p.get('ocupacion')}\n\n---\n\n"
                for m in st.session_state.mode_state["synthetic_chat_history"]:
                    role_label = "Entrevistador" if m['role'] == 'user' else p.get('nombre')
                    chat_content += f"**{role_label}:** {m['content']}\n\n"
                
                pdf_bytes = generate_pdf_html(chat_content, title=f"Entrevista - {p.get('nombre')}", banner_path=banner_file)
                if pdf_bytes:
                    st.download_button("Descargar PDF", data=pdf_bytes, file_name=f"entrevista_{p.get('nombre')}.pdf", use_container_width=True)

            with c2:
                if st.button("Reiniciar Chat", use_container_width=True):
                    st.session_state.mode_state["synthetic_chat_history"] = []
                    st.rerun()

            with c3:
                if st.button("Crear Nuevo Perfil", use_container_width=True, type="secondary"):
                    st.session_state.mode_state.pop("synthetic_persona_data", None)
                    st.session_state.mode_state.pop("synthetic_chat_history", None)
                    st.rerun()
