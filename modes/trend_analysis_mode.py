import streamlit as st
import pandas as pd
import altair as alt
from pytrends.request import TrendReq
from services.gemini_api import call_gemini_stream, call_gemini_api
from utils import render_process_status
from prompts import get_trend_synthesis_prompt
import random
import json

# --- IMPORTS DE LOGS ---
from services.supabase_db import log_query_event
import constants as c

# =====================================================
# MOTOR DE B√öSQUEDA SEM√ÅNTICA (INTEGRADO)
# =====================================================

def smart_internal_search(db, keyword):
    """
    1. Expande la keyword usando IA (Sin√≥nimos/Categor√≠as).
    2. Busca en el repositorio fragmentos que coincidan con CUALQUIERA de los t√©rminos.
    3. Retorna un contexto denso y relevante.
    """
    # 1. Expansi√≥n Sem√°ntica
    expand_prompt = f"Para investigar '{keyword}' en una base de datos de investigaci√≥n de mercados, dame 3 palabras clave adicionales (sin√≥nimos, categor√≠as superiores o temas t√©cnicos relacionados). Solo las palabras separadas por coma, nada m√°s."
    try:
        variants_str = call_gemini_api(expand_prompt)
        variants = [v.strip().lower() for v in variants_str.split(',')]
    except:
        variants = []
    
    search_terms = [keyword.lower()] + variants
    st.caption(f"üïµÔ∏è **Rastreador Interno activado:** Buscando huellas de: *{', '.join(search_terms)}*")

    # 2. Barrido del Repositorio
    hits = []
    
    for doc in db:
        doc_name = doc.get('nombre_archivo', 'Documento sin nombre')
        content_chunks = []
        for grupo in doc.get("grupos", []):
            content_chunks.append(str(grupo.get('contenido_texto', '')))
        
        full_text = " ".join(content_chunks).lower()
        
        # Scoring simple
        score = 0
        matched_terms = []
        for term in search_terms:
            if term in full_text:
                score += 1
                matched_terms.append(term)
        
        if score > 0:
            # Snippet
            start_idx = -1
            for term in matched_terms:
                idx = full_text.find(term)
                if idx != -1:
                    start_idx = idx
                    break
            
            snippet_start = max(0, start_idx - 100)
            snippet_end = min(len(full_text), start_idx + 400)
            snippet = full_text[snippet_start:snippet_end] + "..."
            
            hits.append({
                "doc": doc_name,
                "score": score,
                "snippet": snippet,
                "matches": matched_terms
            })

    # 3. Ordenar
    hits.sort(key=lambda x: x['score'], reverse=True)
    top_hits = hits[:7] 
    
    if not top_hits:
        return ""

    context_str = f"--- RESULTADOS DE B√öSQUEDA INTERNA (T√©rminos: {', '.join(search_terms)}) ---\n\n"
    for hit in top_hits:
        context_str += f"üìÑ **Documento:** {hit['doc']}\n"
        context_str += f"   *Coincidencias:* {', '.join(hit['matches'])}\n"
        context_str += f"   *Fragmento:* \"...{hit['snippet']}...\"\n\n"
        
    return context_str

# =====================================================
# MODO: TREND RADAR 360 (CORREGIDO)
# =====================================================

def calculate_growth(df):
    if df.empty or len(df) < 2: return 0
    first_half = df['Inter√©s'].iloc[:len(df)//2].mean()
    last_half = df['Inter√©s'].iloc[len(df)//2:].mean()
    if first_half == 0: return 100 if last_half > 0 else 0
    return ((last_half - first_half) / first_half) * 100

def google_trends_mode():
    st.subheader("üì° Radar de Tendencias 360¬∞")
    st.markdown("Triangulaci√≥n inteligente: **Mercado** + **Repositorio Sem√°ntico** + **IA**.")

    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        keyword = c1.text_input("T√©rmino:", placeholder="Ej: Sellos Octagonales")
        market = c2.selectbox("Mercado", ["Colombia", "M√©xico", "Global"], index=0)
        timeframe = c3.selectbox("Tiempo", ["today 1-m", "today 12-m", "today 5-y"], format_func=lambda x: "30 D√≠as" if "1-m" in x else "1 A√±o" if "12-m" in x else "5 A√±os")

    geo_map = {"Colombia": "CO", "M√©xico": "MX", "Global": ""}
    geo_code = geo_map[market]

    if st.button("Escanear Tendencia", type="primary", use_container_width=True):
        if not keyword: st.warning("Ingresa un t√©rmino."); return

        trend_df, geo_df = None, None
        rising_queries, related_topics = [], []
        internal_context = ""
        is_simulation = False
        simulation_reason = ""
        
        db = st.session_state.get("db_full", [])

        with render_process_status(f"Analizando '{keyword}'...", expanded=True) as status:
            
            # 1. B√öSQUEDA SEM√ÅNTICA INTERNA
            status.write("üß† Activando puente sem√°ntico con repositorio...")
            if db:
                internal_context = smart_internal_search(db, keyword)
            
            # 2. GOOGLE TRENDS
            status.write("üåç Consultando Google Trends Live...")
            try:
                pytrends = TrendReq(hl='es', tz=300, timeout=(5, 20))
                pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo_code)
                
                data = pytrends.interest_over_time()
                if data.empty: raise ValueError("EmptyData")
                
                trend_df = data.reset_index().rename(columns={keyword: 'Inter√©s', 'date': 'Fecha'})
                
                # Geo
                try:
                    geo_data = pytrends.interest_by_region(resolution='REGION', inc_low_vol=True)
                    geo_data = geo_data[geo_data[keyword] > 0].sort_values(keyword, ascending=False).head(10)
                    if not geo_data.empty: geo_df = geo_data.reset_index().rename(columns={keyword: 'Inter√©s', 'geoName': 'Regi√≥n'})
                except: pass

                # Topics
                try:
                    rel_q = pytrends.related_queries()
                    if rel_q and keyword in rel_q:
                        if rel_q[keyword]['rising'] is not None: rising_queries = rel_q[keyword]['rising'].head(5)['query'].tolist()
                    
                    rel_t = pytrends.related_topics()
                    if rel_t and keyword in rel_t:
                        if rel_t[keyword]['rising'] is not None: related_topics = rel_t[keyword]['rising'].head(5)['topic_title'].tolist()
                except: pass

            except Exception as e:
                is_simulation = True
                simulation_reason = "T√©rmino muy espec√≠fico" if "EmptyData" in str(e) else "Bloqueo API Google"
                
                # Datos Simulados
                dates = pd.date_range(end=pd.Timestamp.now(), periods=52, freq='W')
                values = [min(100, max(0, random.randint(20, 60) + (i * 0.5) + random.randint(-10, 10))) for i in range(52)]
                trend_df = pd.DataFrame({'Fecha': dates, 'Inter√©s': values})
                rising_queries = [f"futuro {keyword}", f"impacto {keyword}", f"novedades {keyword}"]

            # 3. S√çNTESIS
            status.write("üí° Cruzando hallazgos...")
            trend_txt = f"Tendencia {'simulada' if is_simulation else 'real'}. Valor final: {trend_df['Inter√©s'].iloc[-1]}."
            geo_txt = "Datos geo no disponibles." if geo_df is None else str(geo_df.to_dict())
            topics_txt = f"Temas: {', '.join(related_topics)}. Queries: {', '.join(rising_queries)}."
            
            extra = f"NOTA: El usuario busc√≥ '{keyword}'. Google Trends fall√≥ ({simulation_reason}). Asume rol experto." if is_simulation else ""

            prompt = get_trend_synthesis_prompt(keyword, trend_txt + extra, geo_txt, topics_txt, internal_context)
            stream = call_gemini_stream(prompt)
            
            status.update(label="¬°An√°lisis Finalizado!", state="complete", expanded=False)

        # --- DASHBOARD ---
        growth = calculate_growth(trend_df)
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("Inter√©s", f"{int(trend_df['Inter√©s'].iloc[-1])}/100")
        k2.metric("Din√°mica", f"{growth:.1f}%", delta_color="normal" if growth>0 else "inverse")
        k3.metric("Fuente", "Simulaci√≥n IA" if is_simulation else "Google Live")
        k4.metric("Conexi√≥n Interna", "Fuerte" if len(internal_context)>500 else "D√©bil" if len(internal_context)>50 else "Nula", 
                 delta="Hallazgos" if len(internal_context)>50 else "Sin datos")

        if is_simulation: st.warning(f"‚ö†Ô∏è **Modo Estimaci√≥n:** {simulation_reason}. An√°lisis basado en IA.")

        t1, t2, t3 = st.tabs(["Temporal", "Geogr√°fico", "Contexto"])
        
        with t1:
            # CAMBIO: Usamos chart_time en lugar de c para evitar conflictos
            chart_time = alt.Chart(trend_df).mark_area(
                line={'color':'#29B5E8'}, 
                color=alt.Gradient(gradient='linear', stops=[alt.GradientStop(color='#29B5E8', offset=0), alt.GradientStop(color='white', offset=1)], x1=1, x2=1, y1=1, y2=0)
            ).encode(x='Fecha:T', y='Inter√©s:Q', tooltip=['Fecha', 'Inter√©s']).properties(height=300)
            
            st.altair_chart(chart_time, use_container_width=True)
        
        with t2:
            if geo_df is not None:
                st.altair_chart(alt.Chart(geo_df).mark_bar().encode(x='Inter√©s:Q', y=alt.Y('Regi√≥n:N', sort='-x'), color='Inter√©s:Q', tooltip=['Regi√≥n', 'Inter√©s']).properties(height=400), use_container_width=True)
            else: st.caption("Sin datos regionales.")

        with t3:
            if rising_queries:
                st.write("**üî• B√∫squedas relacionadas:**")
                st.markdown(" ".join([f"`{q}`" for q in rising_queries]))
            
            if len(internal_context) > 50:
                st.divider()
                st.markdown("**üóÇÔ∏è Evidencia encontrada en el repositorio:**")
                with st.container(height=200):
                    st.markdown(internal_context)

        st.divider()
        st.markdown("### Brief de Estrategia")
        
        if stream:
            st.write_stream(stream)
            # REGISTRO EN SUPABASE (Ahora funcionar√° porque 'c' es el m√≥dulo constants)
            try:
                log_query_event(f"Trend Radar: {keyword}", mode=c.MODE_TREND_ANALYSIS)
            except Exception as e:
                print(f"Error logging: {e}")
